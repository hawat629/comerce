{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5jHCMjQnRQmBfvtOlBOVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawat629/comerce/blob/master/Defi%20toulouse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN2KUkEpGnlD",
        "colab_type": "text"
      },
      "source": [
        "Cette approche est basée sur l'utilisation de réseaux de neurones auto-encodeurs. \n",
        "Il est basé sur des principes similaires à ceux de l'analyse statistique, mais avec quelques légères différences.\n",
        "\n",
        "Un autoencodeur est un type de réseau neuronal artificiel utilisé pour apprendre des codages de données efficaces sans surveillance. Le but d'un autoencodeur est d'apprendre une représentation (encodage) pour un ensemble de données, typiquement pour la réduction de dimensionnalité. Parallèlement au côté de réduction, un côté de reconstruction est appris, où l'autoencodeur essaie de générer à partir du codage réduit une représentation aussi proche que possible de son entrée d'origine.\n",
        "\n",
        "Sur le plan architectural, la forme la plus simple d'un autoencodeur est un réseau neuronal non récurrent à action directe très similaire aux nombreux perceptrons à couche unique qui fait un perceptron multicouche (MLP) - ayant une couche d'entrée, une couche de sortie et une ou plusieurs couches cachées les reliant - mais avec la couche de sortie ayant le même nombre de nœuds que la couche d'entrée, et dans le but de reconstruire ses propres entrées.\n",
        "en effet on assayer de travailler pas sur les données mes sur les transformés des fouriers des données car c'est le mieux pour des series temporaires ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5mAPx8IHb2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-gvj-hdEXHD",
        "colab_type": "code",
        "outputId": "d187e8b9-e420-40a0-b344-fbbb7b97b880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/Classification/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVG5fbW1EXuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install h5py\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g96B1_qcHfgq",
        "colab_type": "text"
      },
      "source": [
        "on apporte les data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buo4gV0MEX9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = h5py.File(path + \"train.hdf5\", \"r+\")\n",
        "df_train = train[\"dftrain\"]\n",
        "X_train = np.asarray(df_train[\"block0_values\"])\n",
        "test = h5py.File(path + \"test.hdf5\", \"r+\")\n",
        "df_test = test[\"dffinal\"]\n",
        "X_test = np.asarray(df_test[\"block0_values\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNiaxhBWH3dL",
        "colab_type": "text"
      },
      "source": [
        "on trouve les transformés des fouriers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3_FkK1VFYd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_fft = np.fft.fft(X_train)\n",
        "test_fft = np.fft.fft(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-6dyatnH-wF",
        "colab_type": "text"
      },
      "source": [
        "apporter les libraries d'autoencodeur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WIlDP0zGRkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "from keras.layers import Input, Dropout\n",
        "from keras.layers.core import Dense \n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras import regularizers\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTXa7E84EYSJ",
        "colab_type": "code",
        "outputId": "6d1ff5f4-c446-423d-f962-5abea04270cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "seed(10)\n",
        "set_random_seed(10)\n",
        "act_func = 'elu'\n",
        "\n",
        "# Input layer:\n",
        "model=Sequential()\n",
        "# First hidden layer, connected to input vector X. \n",
        "model.add(Dense(10,activation=act_func,\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(0.0),\n",
        "                input_shape=(X_train.shape[1],)\n",
        "               )\n",
        "         )\n",
        "\n",
        "model.add(Dense(2,activation=act_func,\n",
        "                kernel_initializer='glorot_uniform'))\n",
        "\n",
        "model.add(Dense(10,activation=act_func,\n",
        "                kernel_initializer='glorot_uniform'))\n",
        "\n",
        "model.add(Dense(X_train.shape[1],\n",
        "                kernel_initializer='glorot_uniform'))\n",
        "\n",
        "model.compile(loss='mse',optimizer='adam')\n",
        "\n",
        "# Train model for 100 epochs, batch size of 10: \n",
        "NUM_EPOCHS=100\n",
        "BATCH_SIZE=10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtd00ozJEYaN",
        "colab_type": "code",
        "outputId": "d870005e-1473-4a7f-ebab-9528c7f1739d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(np.array(train_fft),np.array(train_fft),\n",
        "                  batch_size=BATCH_SIZE, \n",
        "                  epochs=NUM_EPOCHS,\n",
        "                  validation_split=0.05,\n",
        "                  verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1593 samples, validate on 84 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:85: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1593/1593 [==============================] - 6s 4ms/step - loss: 27348.4846 - val_loss: 11239.1025\n",
            "Epoch 2/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27304.6924 - val_loss: 11236.3093\n",
            "Epoch 3/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27241.2017 - val_loss: 11240.1796\n",
            "Epoch 4/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27240.6297 - val_loss: 11232.4365\n",
            "Epoch 5/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27417.3670 - val_loss: 11234.7539\n",
            "Epoch 6/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27124.9895 - val_loss: 11242.1516\n",
            "Epoch 7/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27115.6801 - val_loss: 11238.6235\n",
            "Epoch 8/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26973.6492 - val_loss: 11248.7369\n",
            "Epoch 9/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26963.0302 - val_loss: 11280.9668\n",
            "Epoch 10/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 27212.0400 - val_loss: 11247.5108\n",
            "Epoch 11/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27293.6236 - val_loss: 11243.9874\n",
            "Epoch 12/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 27239.2051 - val_loss: 11242.7111\n",
            "Epoch 13/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 27220.2907 - val_loss: 11240.1002\n",
            "Epoch 14/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 27195.0317 - val_loss: 11237.7605\n",
            "Epoch 15/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 27137.5224 - val_loss: 11240.5829\n",
            "Epoch 16/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 27077.3020 - val_loss: 11242.9830\n",
            "Epoch 17/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26988.0351 - val_loss: 11244.7311\n",
            "Epoch 18/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26899.7798 - val_loss: 11253.5280\n",
            "Epoch 19/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26807.6817 - val_loss: 11256.2634\n",
            "Epoch 20/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26845.2400 - val_loss: 11258.1983\n",
            "Epoch 21/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26810.0699 - val_loss: 11243.0774\n",
            "Epoch 22/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26618.5699 - val_loss: 11261.0562\n",
            "Epoch 23/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26771.0678 - val_loss: 11235.6544\n",
            "Epoch 24/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26702.9059 - val_loss: 11239.4013\n",
            "Epoch 25/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26570.1855 - val_loss: 11253.3457\n",
            "Epoch 26/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26558.1198 - val_loss: 11248.6033\n",
            "Epoch 27/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26549.7949 - val_loss: 11244.5345\n",
            "Epoch 28/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26509.2631 - val_loss: 11247.2299\n",
            "Epoch 29/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26765.1226 - val_loss: 11250.0243\n",
            "Epoch 30/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26655.8242 - val_loss: 11246.9402\n",
            "Epoch 31/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26474.6804 - val_loss: 11242.4821\n",
            "Epoch 32/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26545.9267 - val_loss: 11242.2044\n",
            "Epoch 33/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26527.8532 - val_loss: 11244.6216\n",
            "Epoch 34/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26491.4354 - val_loss: 11338.7229\n",
            "Epoch 35/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26571.9668 - val_loss: 11332.6321\n",
            "Epoch 36/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26404.0937 - val_loss: 11351.4661\n",
            "Epoch 37/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26473.0576 - val_loss: 11336.5490\n",
            "Epoch 38/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26471.9245 - val_loss: 11340.1433\n",
            "Epoch 39/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26518.2281 - val_loss: 11315.8330\n",
            "Epoch 40/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26446.0118 - val_loss: 11320.4658\n",
            "Epoch 41/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26417.7199 - val_loss: 11296.1743\n",
            "Epoch 42/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26397.2030 - val_loss: 11306.1214\n",
            "Epoch 43/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26517.4077 - val_loss: 11352.8657\n",
            "Epoch 44/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26698.8076 - val_loss: 11290.6717\n",
            "Epoch 45/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26443.1715 - val_loss: 11306.2555\n",
            "Epoch 46/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26372.0096 - val_loss: 11283.6844\n",
            "Epoch 47/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26372.0051 - val_loss: 11296.6104\n",
            "Epoch 48/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26397.5612 - val_loss: 11331.8503\n",
            "Epoch 49/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26363.3828 - val_loss: 11317.2919\n",
            "Epoch 50/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26411.5806 - val_loss: 11327.4783\n",
            "Epoch 51/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26343.2440 - val_loss: 11314.8398\n",
            "Epoch 52/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26280.6132 - val_loss: 11303.1337\n",
            "Epoch 53/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26345.1916 - val_loss: 11295.4924\n",
            "Epoch 54/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26443.9815 - val_loss: 11286.9947\n",
            "Epoch 55/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26365.3926 - val_loss: 11305.5363\n",
            "Epoch 56/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26381.9493 - val_loss: 11276.5597\n",
            "Epoch 57/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26353.1094 - val_loss: 11295.5900\n",
            "Epoch 58/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26367.5867 - val_loss: 11299.6240\n",
            "Epoch 59/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26416.5286 - val_loss: 11237.1131\n",
            "Epoch 60/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26463.0195 - val_loss: 11236.9851\n",
            "Epoch 61/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26359.1785 - val_loss: 11236.5801\n",
            "Epoch 62/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26253.8458 - val_loss: 11236.4437\n",
            "Epoch 63/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26398.8322 - val_loss: 11236.6212\n",
            "Epoch 64/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26320.9826 - val_loss: 11237.4895\n",
            "Epoch 65/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26366.9297 - val_loss: 11237.2992\n",
            "Epoch 66/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26404.0025 - val_loss: 11240.8573\n",
            "Epoch 67/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26317.0340 - val_loss: 11245.0386\n",
            "Epoch 68/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26285.0749 - val_loss: 11240.6107\n",
            "Epoch 69/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26256.1995 - val_loss: 11240.9672\n",
            "Epoch 70/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26254.6352 - val_loss: 11241.0660\n",
            "Epoch 71/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26272.4356 - val_loss: 11244.1875\n",
            "Epoch 72/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26330.3995 - val_loss: 11249.0986\n",
            "Epoch 73/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26361.2931 - val_loss: 11241.7973\n",
            "Epoch 74/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26426.9124 - val_loss: 11240.0249\n",
            "Epoch 75/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26331.9093 - val_loss: 11240.8062\n",
            "Epoch 76/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26289.9629 - val_loss: 11238.6736\n",
            "Epoch 77/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26341.3995 - val_loss: 11239.8430\n",
            "Epoch 78/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26262.5398 - val_loss: 11237.2533\n",
            "Epoch 79/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26290.5714 - val_loss: 11238.3401\n",
            "Epoch 80/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26321.1004 - val_loss: 11237.3507\n",
            "Epoch 81/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26316.7711 - val_loss: 11237.4320\n",
            "Epoch 82/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26243.8640 - val_loss: 11237.4338\n",
            "Epoch 83/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26329.0003 - val_loss: 11237.2206\n",
            "Epoch 84/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26290.4425 - val_loss: 11237.3476\n",
            "Epoch 85/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26216.4941 - val_loss: 11237.4633\n",
            "Epoch 86/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26263.2900 - val_loss: 11237.5908\n",
            "Epoch 87/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26252.7357 - val_loss: 11237.0756\n",
            "Epoch 88/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26269.3112 - val_loss: 11237.2426\n",
            "Epoch 89/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26268.6686 - val_loss: 11236.7680\n",
            "Epoch 90/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26408.8269 - val_loss: 11237.1571\n",
            "Epoch 91/100\n",
            "1593/1593 [==============================] - 5s 3ms/step - loss: 26222.1402 - val_loss: 11236.7128\n",
            "Epoch 92/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26280.1566 - val_loss: 11237.0723\n",
            "Epoch 93/100\n",
            "1593/1593 [==============================] - 6s 3ms/step - loss: 26292.1781 - val_loss: 11237.2980\n",
            "Epoch 94/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26317.7786 - val_loss: 11237.0813\n",
            "Epoch 95/100\n",
            "1593/1593 [==============================] - 7s 5ms/step - loss: 26375.8483 - val_loss: 11236.8716\n",
            "Epoch 96/100\n",
            "1593/1593 [==============================] - 7s 4ms/step - loss: 26228.0465 - val_loss: 11236.6325\n",
            "Epoch 97/100\n",
            "1593/1593 [==============================] - 7s 4ms/step - loss: 26306.8668 - val_loss: 11238.0374\n",
            "Epoch 98/100\n",
            "1593/1593 [==============================] - 7s 4ms/step - loss: 26270.7642 - val_loss: 11237.9471\n",
            "Epoch 99/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26277.0051 - val_loss: 11240.6535\n",
            "Epoch 100/100\n",
            "1593/1593 [==============================] - 6s 4ms/step - loss: 26267.7266 - val_loss: 11240.2605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuwlL15pLD6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set(color_codes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-o6CsB1Ie_E",
        "colab_type": "text"
      },
      "source": [
        "on plot l'histograme pour savoir choisir un treshold convenable au donné."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UARuqcwJsGD",
        "colab_type": "code",
        "outputId": "268c11cd-fea2-4ef7-8779-06506b102f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "X_pred = model.predict(train_fft)\n",
        "X_pred = pd.DataFrame(X_pred, \n",
        "                      columns=pd.DataFrame(train_fft).columns)\n",
        "X_pred.index = pd.DataFrame(train_fft).index\n",
        "\n",
        "scored = pd.DataFrame(index= pd.DataFrame(train_fft).index)\n",
        "scored['Loss_mae'] = np.mean(np.abs(X_pred-train_fft), axis = 1)\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.distplot(scored['Loss_mae'],\n",
        "             bins = 150, \n",
        "             kde= True,\n",
        "            color = 'blue');\n",
        "plt.xlim([0.0,300])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:85: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAF5CAYAAACoQHq9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1008x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBG_SPQ_EYjb",
        "colab_type": "code",
        "outputId": "b7a784b0-adfd-4aba-acda-1d32e003b679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "X_pred = model.predict(test_fft)\n",
        "X_pred = pd.DataFrame(X_pred, \n",
        "                      columns=pd.DataFrame(test_fft).columns)\n",
        "X_pred.index = pd.DataFrame(test_fft).index\n",
        "\n",
        "scored = pd.DataFrame(index=pd.DataFrame(test_fft).index)\n",
        "scored['Loss_mae'] = np.mean(np.abs(X_pred-pd.DataFrame(test_fft)), axis = 1)\n",
        "scored['Threshold'] = 200\n",
        "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
        "scored.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:85: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss_mae</th>\n",
              "      <th>Threshold</th>\n",
              "      <th>Anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.872632</td>\n",
              "      <td>200</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.679184</td>\n",
              "      <td>200</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>139.499716</td>\n",
              "      <td>200</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.123840</td>\n",
              "      <td>200</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.470415</td>\n",
              "      <td>200</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Loss_mae  Threshold  Anomaly\n",
              "0    7.872632        200    False\n",
              "1    3.679184        200    False\n",
              "2  139.499716        200    False\n",
              "3    3.123840        200    False\n",
              "4    6.470415        200    False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo2KspXTIwWb",
        "colab_type": "text"
      },
      "source": [
        "list des indices d'anomalies detectés\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXrkntb3Mjaz",
        "colab_type": "code",
        "outputId": "a399e0c8-6e49-4221-832e-fe06acc91022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#nombre d'anomalie detecter\n",
        "N = 0\n",
        "for i in range (1917):\n",
        "    if (scored['Loss_mae'][i] > 150): \n",
        "        N = N+1\n",
        "        print(i)\n",
        "N"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "24\n",
            "37\n",
            "46\n",
            "49\n",
            "54\n",
            "70\n",
            "115\n",
            "159\n",
            "165\n",
            "167\n",
            "195\n",
            "198\n",
            "225\n",
            "227\n",
            "230\n",
            "256\n",
            "262\n",
            "268\n",
            "284\n",
            "301\n",
            "321\n",
            "322\n",
            "323\n",
            "330\n",
            "364\n",
            "366\n",
            "367\n",
            "376\n",
            "382\n",
            "395\n",
            "447\n",
            "453\n",
            "458\n",
            "493\n",
            "503\n",
            "511\n",
            "520\n",
            "549\n",
            "557\n",
            "576\n",
            "591\n",
            "595\n",
            "596\n",
            "630\n",
            "654\n",
            "668\n",
            "675\n",
            "691\n",
            "693\n",
            "696\n",
            "709\n",
            "730\n",
            "760\n",
            "764\n",
            "785\n",
            "813\n",
            "822\n",
            "840\n",
            "841\n",
            "854\n",
            "856\n",
            "863\n",
            "871\n",
            "883\n",
            "921\n",
            "931\n",
            "947\n",
            "974\n",
            "979\n",
            "1005\n",
            "1017\n",
            "1030\n",
            "1042\n",
            "1044\n",
            "1062\n",
            "1085\n",
            "1094\n",
            "1101\n",
            "1129\n",
            "1139\n",
            "1176\n",
            "1223\n",
            "1226\n",
            "1227\n",
            "1269\n",
            "1273\n",
            "1291\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1330\n",
            "1331\n",
            "1341\n",
            "1346\n",
            "1352\n",
            "1356\n",
            "1359\n",
            "1370\n",
            "1377\n",
            "1390\n",
            "1394\n",
            "1461\n",
            "1490\n",
            "1500\n",
            "1502\n",
            "1514\n",
            "1528\n",
            "1539\n",
            "1540\n",
            "1548\n",
            "1555\n",
            "1571\n",
            "1579\n",
            "1592\n",
            "1596\n",
            "1607\n",
            "1612\n",
            "1621\n",
            "1628\n",
            "1639\n",
            "1654\n",
            "1655\n",
            "1661\n",
            "1673\n",
            "1684\n",
            "1685\n",
            "1698\n",
            "1715\n",
            "1727\n",
            "1730\n",
            "1735\n",
            "1746\n",
            "1777\n",
            "1779\n",
            "1788\n",
            "1794\n",
            "1806\n",
            "1829\n",
            "1838\n",
            "1853\n",
            "1862\n",
            "1870\n",
            "1877\n",
            "1891\n",
            "1892\n",
            "1894\n",
            "1895\n",
            "1899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f81PDE83TF4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}